{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Embedded Deployment: Tiny ViT (32×32) → Human/Not-Human\n",
        "\n",
        "This notebook guides you through exporting a minimal ViT-like classifier to embedded/edge devices and running optimized inference.\n",
        "\n",
        "## Steps\n",
        "1. Define & test tiny model with dummy weights\n",
        "2. Export to ONNX / TFLite\n",
        "3. Quantize to INT8 (if desired)\n",
        "4. Run on device (MCU via TFLite Micro, or ARM via ONNX Runtime)\n",
        "\n",
        "## References\n",
        "- TensorFlow Lite Micro: https://www.tensorflow.org/lite/microcontrollers\n",
        "- ONNX Runtime: https://onnxruntime.ai/\n",
        "- TVM: https://tvm.apache.org/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export & quick host inference\n",
        "import torch\n",
        "from tiny_vit_embedded import TinyViT32, export_onnx\n",
        "\n",
        "model = TinyViT32()\n",
        "# Quick host inference\n",
        "x = torch.randn(1, 3, 32, 32)\n",
        "prob = model(x)\n",
        "print('Host prob:', float(prob))\n",
        "\n",
        "# Export ONNX\n",
        "onnx_path = export_onnx(model, 'tiny_vit32.onnx')\n",
        "print('ONNX saved to:', onnx_path)\n",
        "\n",
        "# Optional: run ONNXRuntime on host (if installed)\n",
        "try:\n",
        "    import onnxruntime as ort\n",
        "    import numpy as np\n",
        "    sess = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])\n",
        "    out = sess.run(['prob'], {'input': x.numpy().astype('float32')})\n",
        "    print('ONNXRuntime prob:', float(out[0][0,0]))\n",
        "except Exception as e:\n",
        "    print('ONNXRuntime not available:', e)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
